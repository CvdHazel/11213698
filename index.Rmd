---
title: "Portfolio Computational Musicology"
author: "Chayenne van den Hazel"
date: "3 maart 2019"
output: 
    flexdashboard::flex_dashboard:
        storyboard: true
        theme: lumen
        
---

```{r}
library(tidyverse)
library(tidymodels)
library(protoclust)
library(heatmaply)
library(spotifyr)
library(ggdendro)
library(compmus)
source('spotify.R')
```

### What is this storyboard about? 

![Bring Me The Horizon](bmth.jpg)

***

The metalband Bring Me The Horizon released their sixth album *amo* on the 25th of January 2019. The reaction on the new album is divided. The sound of this album is totally different than fans are used to hearing from them. It feels like they are stepping out of their 'heavy metal' image and taking on a new one. Besides that, it is said that the album is not cohesive because of the many styles of music being incorporated. One song called 'heavy metal' of BMTH's new album talks about their change in genre and the reaction of their fans:


*"And I keep picking petals
I'm afraid you don't love me anymore
'Cause a kid on the 'gram in a Black Dahlia tank
Says it ain't heavy metal"*


I want to know if their new album is really that different from the other albums and what the difference is exactly. Is it true that they are changing their image and what are they changing it to? My research question is therefore: Is Bring Me The Horizon creating a new musical image and what is this image exactly?


To anwer my research question I'm using a handfull of different Spofity playlists to compare their features. My main corpus is obviously BMTH's newest album *amo*. Besides that I'm also looking into all their old albums: *Count Your Blessings*, *Suidice Season*, *There is a Hell Believe Me I've Seen it. There is a Heaven Let's Keep it a Secret*, *Sempiternal* and *That's the Spirit*. To get the Spotify features for the albums, I've make seperate playlist for each. With the help of these albums I can compare the new album to their old ones and see what the differences and similarities are. 


This will hopefully answer the first part of my research question, but more is needed to answer the second. Different musical genres can help me figure out what it is that BMTH is changing their image into. I'm going to use different Spotify playlists to compare them to the albums and see which genre fits the best per album. The playlist I'm using for this are: Rock Classics, Pure Pop Punk, Heavy Metal, Pop Internacional and Ultimate Indie. 


By combining these two elements, the BMTH albums and different genre playlist, I hope to answer my research question. For more information about the albums, the playlists being used and audio samples: see the Appendix. 


### Is Bring Me The Horizon's newest album really that different from the others?

```{r}
# Data Spotify features 

blessings <- get_playlist_audio_features('faaske', '3q4J2ymyPxuRH49FUexRDA')
amo <- get_playlist_audio_features('faaske', '1GEk4D55A3EI7uKAcr1N0w')
spirit <- get_playlist_audio_features('faaske', '4cIxKAxJ55NmI5Cz5Gp1jn')
sempiternal <- get_playlist_audio_features('faaske', '0lNxfrMHxBMcUnQps2DkeU')
hell <- get_playlist_audio_features('faaske', '0SIOLbQcEkakGKEmClItXd')
suicide <- get_playlist_audio_features('faaske', '0RSC1KIQe8DOpLGdgKZLcE')


# Combine data sets

albums <-
    blessings %>% mutate(album = "1. Count your blessings") %>%
    bind_rows(amo %>% mutate(album = "6. amo")) %>%
    bind_rows(spirit %>% mutate(album = "5. That's the Spirit")) %>%
    bind_rows(sempiternal %>% mutate(album = "4. Sempiternal")) %>%
    bind_rows(hell %>% mutate(album = "3. There is a Hell...")) %>%
    bind_rows(suicide %>% mutate(album = "2. Suicide Season"))

#Plot valence/energy for all albums

ve_album <- albums %>%                      
    ggplot(                   
        aes(
            x = valence,
            y = energy,
            size = loudness,
            colour = album,
            label = track_name 
        )
    ) +
    geom_point(alpha = 0.8) +               
    geom_rug(size = 0.1) +       
    scale_x_continuous(          
        limits = c(0, 1),
        breaks = c(0, 0.50, 1),  
        minor_breaks = NULL     
    ) +
    scale_y_continuous(          
        limits = c(0, 1),
        breaks = c(0, 0.50, 1),
        minor_breaks = NULL
    ) +
    scale_colour_brewer(         
        type = "qual",           
        palette = "Paired"       
    ) +
    scale_size_continuous(       
        trans = "exp",
        guide = "none"
    ) +
    theme_light() +              
    labs(                        
        x = "Valence",
        y = "Energy",
        colour = "Album"
    )

ggplotly(ve_album)

# Genres

bmth <- get_playlist_audio_features('faaske', '6ya8YDyX7ldJsG1OtYWhl4')

heavymetal_genre <-get_playlist_audio_features('spotify', '37i9dQZF1DX9qNs32fujYe')
pop_genre <- get_playlist_audio_features('spotify', '37i9dQZF1DX1ngEVM0lKrb')
indie_genre <- get_playlist_audio_features('spotify', '37i9dQZF1DX2Nc3B70tvx0')
punk_genre <- get_playlist_audio_features('spotify', '37i9dQZF1DXasneILDRM7B')
rock_genre <- get_playlist_audio_features('spotify', '37i9dQZF1DWXRqgorJj26U')

genre <-
    heavymetal_genre %>% mutate(genre = "Heavy Metal") %>%
    bind_rows(pop_genre %>% mutate(genre = "Pop")) %>%
    bind_rows(indie_genre %>% mutate(genre= "Indie")) %>%
    bind_rows(punk_genre %>% mutate(genre = "Punk")) %>%
    bind_rows(rock_genre %>% mutate(genre = "Rock"))

ve_genre <- genre %>%                      
    ggplot(                   
        aes(
            x = valence,
            y = energy,
            size = loudness,
            colour = genre,
            label = track_name 
        )
    ) +
    geom_point(alpha = 0.8) +               
    geom_rug(size = 0.1) +       
    scale_x_continuous(          
        limits = c(0, 1),
        breaks = c(0, 0.50, 1),  
        minor_breaks = NULL     
    ) +
    scale_y_continuous(          
        limits = c(0, 1),
        breaks = c(0, 0.50, 1),
        minor_breaks = NULL
    ) +
    scale_colour_brewer(         
        type = "qual",           
        palette = "Paired"       
    ) +
    scale_size_continuous(       
        trans = "exp",
        guide = "none"
    ) +
    theme_light() +              
    labs(                        
        x = "Valence",
        y = "Energy",
        colour = "Genre"
    )

ggplotly(ve_genre)

```

***

In this graph, the Spotify features 'Valence' and 'Energy' are plotted against eachother for all the albums Bring Me The Horizon has made and the loudness of the songs is shown by the size of the dots. Valence and energy are measured on a scale from 0 to 1. Valence shows how positive a track is, so with a score of 0 a track is really negative and a really positivie track will store 1. The general distribution for valence is fairly average, so most tracks score between 0.4 and 0.6. The intensity and activity of a track is shown by the energy feature. Spotify says that energetic tracks, so tracks that score high on the scale, are fast, loud and noisy like death metal. When looking at the distribution for this feature, most tracks have a score of 0.8. Loudness has a different scale than the other features. It is measured in decibles (dB) and typically ranges from -60 to 0 dB. In general, the loudness of a track is measured between -10 and -5 on average. 


As can be seen in the graph on the left, BMTH's music mostly scores below 0.5 on valence and in general scores really high on energy. An interesting finding in this graph is the shift in valence between the first and last few albums. The first album *Count your blessings* scores low on valence, like most of their songs in general. But looking at the last two albums *That's the Spirit* and *amo*, it can be seen that those songs score the highest on valence. Therefore it can be said that the outliers on the valence scale for all BMTH songs, are actually the songs of these last two albums. When looking at the energy scale, there are three main outliers: a song called 'Memorial' from *There is a Hell...*, 'i apologise if you feel something' from *amo* and 'Fifteen Fantoms, Counting' from *Count your Blessings*. 'Memorial' and 'Fifteen Fantoms, Counting' are both slow instrumental songs and that's the reason they score lower on energy than the rest of the songs. 'i apologise if you feel somthing' is not totally instrumental, but it is a slower song compared to the rest of the album. This songs is also used as the intro to Bring Me The Horizon's concert, which is not surprising because it sounds very mysterious. 


Loudness is also an interessting feature to look into. The legend shows that *Sempiternal* scores the hightest and the three older albums score the lowest out of all 6 albums. This is a surprise because the first few albums are definatly considered metal and I would think that those songs would score high on the loudness scale. 

  
### An structural analysis of 'heavy metal' and Heavy Metal

```{r}

# heavy metal Chroma- and Cepstrogram

heavymetal_song <- 
    get_tidy_audio_analysis('6baGTtDakSNvUfW3FJd8yX') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'acentre', norm = 'manhattan')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))

heavymetal_song_plot <- 
    bind_rows(
        heavymetal_song %>% compmus_self_similarity(pitches, 'aitchison') %>% mutate(d = d / max(d), type = "Chroma"),
        heavymetal_song %>% compmus_self_similarity(timbre, 'euclidean') %>% mutate(d = d / max(d), type = "Timbre")) %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    facet_wrap(~ type) +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '') +
    ggtitle("heavy metal by BMTH")

# walk Chroma- and Cepstrogram

walk_song <- 
    get_tidy_audio_analysis('7fcfNW0XxTWlwVlftzfDOR') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'acentre', norm = 'manhattan')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))

walk_song_plot <- 
    bind_rows(
        walk_song %>% compmus_self_similarity(pitches, 'aitchison') %>% mutate(d = d / max(d), type = "Chroma"),
        walk_song %>% compmus_self_similarity(timbre, 'euclidean') %>% mutate(d = d / max(d), type = "Timbre")) %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    facet_wrap(~ type) +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')+
    ggtitle("walk by Pantera")

```


***

Before we looked at the cepstrograms between 'heavy metal' by Bring Me The Horizon and 'walk' by Pantera. These graphs are Self-Similarity Martices based on timbre. Different than the cepstrograms, here we don't see as much differences between the two songs. The horizontal and vertical yellow lines cross about the same time for both songs, this is where in both songs the bridge comes in. In 'heavy metal' the bridge consist of a beatbox section where all the other instruments are dropped. The same happens in 'walk', but instead of a beatbox section, a guitar solo is added with drums. Beatboxing imitates instruments and my guess is that therefore the crossing yellow lines in 'heavy metal' are less clear than in 'walk', where there are just two instruments present in the bridge. 


### Chromagrams? or Cepstrograms?

```{r}


    
```

***
Here you can see two chromagrams and two ceptrograms. I've chosen two songs to compare to eachother, one song from BMTH and a metal song by a different band. The top ones are based on the song 'heavy metal' by BMTH, which is a song from their newest album *amo*. The reason why I chose this song is because of the song title. Like I stated before, BMTH was considered a metalband, but that is not necessary what people say about them nowadays. That's why it will be interessting to compare this song to a 'real' metal song and see if they are very different or similar. The other song is calles 'walk' by Pantara, an American groovemetalband who are known as trendsetters in their genre in the nineties. I've chosen this song to compare to 'heavy metal' because it is the most popular song in the Heavy Metal Spotify playlist. 


From a quick glance, the differences between these songs, regarding these graphs, can immidately be seen. The chromagrams for the songs are almost the opposite of eachother. 


Looking at timbre, the difference between the songs are even more clear. 'heavy metal''s cepstrogram is almost totally yellow, with a few darker bandings in c04 and c06. 'walk' is the exact opposite. Blue is much more present and only c02 and c01 have a yellow tone. 



### Are key changes more common in the past or present?

```{r}

# Code

circshift <- function(v, n) {if (n == 0) v else c(tail(v, n), head(v, -n))}
                                    
    # C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B 
major_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <- 
    c(1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <- 
    c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
    c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

key_templates <-
    tribble(
        ~name    , ~template,
        'Gb:maj', circshift(major_key,  6),
        'Bb:min', circshift(minor_key, 10),
        'Db:maj', circshift(major_key,  1),
        'F:min' , circshift(minor_key,  5),
        'Ab:maj', circshift(major_key,  8),
        'C:min' , circshift(minor_key,  0),
        'Eb:maj', circshift(major_key,  3),
        'G:min' , circshift(minor_key,  7),
        'Bb:maj', circshift(major_key, 10),
        'D:min' , circshift(minor_key,  2),
        'F:maj' , circshift(major_key,  5),
        'A:min' , circshift(minor_key,  9),
        'C:maj' , circshift(major_key,  0),
        'E:min' , circshift(minor_key,  4),
        'G:maj' , circshift(major_key,  7),
        'B:min' , circshift(minor_key, 11),
        'D:maj' , circshift(major_key,  2),
        'F#:min', circshift(minor_key,  6),
        'A:maj' , circshift(major_key,  9),
        'C#:min', circshift(minor_key,  1),
        'E:maj' , circshift(major_key,  4),
        'G#:min', circshift(minor_key,  8),
        'B:maj' , circshift(major_key, 11),
        'D#:min', circshift(minor_key,  3))

# Keygram for 'sugar honey ice & tea' 

sugar_key <- 
    get_tidy_audio_analysis('3Ddgh4ZwVIkLx0f4WeDFmo') %>% 
    compmus_align(sections, segments) %>% 
    select(sections) %>% unnest(sections) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'))

sugar_keygram <-
sugar_key  %>% 
    compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>% 
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '') +
    ggtitle("'sugar honey ice & tea' from amo")

# Keygram for Pray for Plagues 

pray_key <- 
    get_tidy_audio_analysis('0zYxfgyqypkG7rRwFqyisT') %>% 
    compmus_align(sections, segments) %>% 
    select(sections) %>% unnest(sections) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'))

pray_keygram <-
pray_key  %>% 
    compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>% 
    ggplot(
        aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
    geom_tile() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_minimal() +
    labs(x = 'Time (s)', y = '') +
    ggtitle("'Pray for Plagues' from Count your Blessings")


```

***

On the left two keygrams are shown for two different songs by Bring Me The Horizon. The first is a key visualization of the most popular song from *amo* 'sugar honey ice & tea' and the second one is the most popular song from *Count your Blessings* 'Pray for Plagues'. While the bridge in  'sugar honey ice & tea' comes in a bit later than the one in 'Pray for Plagues', they both have one. Both bridges drop a lot of the instruments that can be heard in the rest of the song and slowing it down, making it include less chords at that moment. Also similar in both songs is the usage of the chords. The chords that are used the most are used throughout the whole song, so there is no modulation present. 

### Which genre has a track most in common?

```{r}

rock <- 
    get_playlist_audio_features('spotify', '37i9dQZF1DWXRqgorJj26U') %>% 
    slice(1:20) %>% 
    add_audio_analysis
punk <- 
    get_playlist_audio_features('spotify', '37i9dQZF1DXasneILDRM7B') %>% 
    slice(1:20) %>% 
    add_audio_analysis
heavymetal <- 
    get_playlist_audio_features('spotify', '37i9dQZF1DX9qNs32fujYe') %>% 
    slice(1:20) %>% 
    add_audio_analysis
pop <- 
    get_playlist_audio_features('spotify', '37i9dQZF1DX1ngEVM0lKrb') %>% 
    slice(1:20) %>% 
    add_audio_analysis
indie <- 
    get_playlist_audio_features('spotify', '37i9dQZF1DX2Nc3B70tvx0') %>% 
    slice(1:20) %>% 
    add_audio_analysis

genre <- 
    rock %>% mutate(genre = "Rock") %>% 
    bind_rows(
        punk %>% mutate(genre = "Punk"),
        pop %>% mutate(genre = "Pop"),
        indie %>% mutate(genre = "Indie"),
        heavymetal %>% mutate(genre = "Heavy Metal")) %>% 
    mutate(genre = factor(genre)) %>% 
    mutate(
        segments = 
            map2(segments, key, compmus_c_transpose)) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>% 
    mutate_at(vars(pitches, timbre), map, bind_rows) %>% 
    unnest(pitches, timbre)

genre_juice <- 
    recipe(genre ~
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration_ms +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = genre) %>% 
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    # step_range(all_predictors()) %>% 
    prep(genre) %>% 
    juice
genre_cv <- genre_juice %>% vfold_cv(10)
genre_knn <- nearest_neighbor(neighbors = 1) %>% set_engine('kknn')
predict_knn_reduced <- function(split)
    fit(
        genre_knn, 
        genre ~ c01 + c02 + energy + danceability + tempo, 
        data = analysis(split)) %>% 
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
genre_cv %>% 
    mutate(pred = map(splits, predict_knn_reduced)) %>% unnest(pred) %>% 
    conf_mat(truth = genre, estimate = .pred_class) %>% 
    autoplot(type = 'mosaic')


```



***

I want to use a classifier to find out which genre fits a song the best. If, for example, a song from *Count your Blessings* is closest to the heavy metal genre and a song from *amo* is closest to pop, this will give a good argument in favor of my research question. I have struggled a lot with this weeks homework, because I wasn't able to attend the class. I was able to make the visualizations on the right by using the compmus document, but I wasn't able to make them how I wanted it to and I had trouble reading them. I'm going to work on this for my final portfolio. 

### Clustering

```{r}

# Clustering

bmth_songs <- 
    get_playlist_audio_features('faaske', '6ya8YDyX7ldJsG1OtYWhl4') %>% 
    add_audio_analysis %>% 
    mutate(
        segments = 
            map2(segments, key, compmus_c_transpose)) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>% 
    mutate_at(vars(pitches, timbre), map, bind_rows) %>% 
    unnest(pitches, timbre)

# Pre-Processing 

bmth_songs_juice <- 
    recipe(track_name ~
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration_ms +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = bmth_songs) %>% 
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    # step_range(all_predictors()) %>% 
    prep(bmth_songs %>% mutate(track_name = str_trunc(track_name, 20))) %>% 
    juice %>% 
    column_to_rownames('track_name')

# Computing distances

bmth_dist <- dist(bmth_songs_juice, method = 'euclidean')

# Hierarchical clustering

protoclust(bmth_dist) %>% dendro_data %>% ggdendrogram


```


*** 

On the first picture we see a clustering of the 69 Bring Me The Horizon songs from all 6 albums. By looking at it we can devide the songs into four sections:
1) From 'Memorial' till 'The Sadness Will Never End'
2) From 'wonderful life' till 'Sleep With One Eye Open'
3) From 'Don't Go' till 'Liquor & Love Lost'
4) From 'ouch' till 'Run' 
The first section can be considered as 'the rest' and so I will focus on the other three sections. 

The 4th section is made up of songs from the last three albums (*Sempiternal*, *That's the Spirit* and *amo*). All the songs from *That's the Spirit* are in this 4th section and the majority of *amo* as well, but for *Sempiternal* this is not the section with the most songs in them. 

*Sempiternal* scores the highest in the 2nd section, with 6 songs from 20 songs in that section. For *Count your Blessings* this section includes the majority of their songs as well (5 songs from the 10 songs on the album). 

When looking at the 3rd section, *There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep it a Secret* stands out with 8 songs out of 17 in this section. All the other albums except for *That's the Spirit* also have a few songs in this section. 

In general, the most recent albums are clustered together in one section and the older albums are clustered in others. This is very interessting, because it shows that the newer albums are different than the older ones and in such a manner that they (in general) won't cluster with eachother until very high up in the graph. 


### Heatmap

```{r}


# Heatmap

grDevices::dev.size("px")
heatmaply(
    bmth_songs_juice,
    hclustfun = hclust,
    # hclustfun = protoclust,
    # Comment out the hclust_method line when using protoclust.
    hclust_method = 'average',
    dist_method = 'euclidean')

```
***

### Conclusion 

By comparing the different albums of BMTH with eachother, it is clear that their newest album *amo* is different than the rest. The songs score higher on valence than the songs from older albums, which means they sound more 'positive'. 

When looking at the structure of songs from *amo* they are different from.... and similar in a way.....

It looks like a lot of newer songs cluster together.

All of these visualizations show that *amo* is clearly different than the older albums and is pulling away from the heavy metal image there was before. When looking at the visualizations though, the differences aren't that different. A lot of songs still have similar elements in them, but are just mixed with a lot of other genres. 

I think, BMTH shows a whole different side of them. They can do more than bang their heads and get people involved in moshpits. They are multitalented in regards of musical genres and are exploring wiht them. The reaction of fans might be scaddered, but the new 'image' might be an oppertunity to expand the fanbase. 

***

### Appendix 

In the 15 years Bring Me The Horizon has been an official band, they have released 6 albums. Below you'll see a table with the album names, the year of their release and the number of songs on the album. 


| Album Name                                                                        | Year of release | Number of songs |
|-----------------------------------------------------------------------------------|:---------------:|:---------------:|
| Count your Blessings                                                              |             2006|               10|
| Suicide Season                                                                    |             2008|               10|
| There is a Hell Believe Me I've Seen It. There is a Heaven Let's Keep It a Secret |             2010|               12|
| Sempiternal                                                                       |             2013|               13|
| That's the Spirit                                                                 |             2015|               11|
| amo                                                                               |             2019|               13|



Below you'll see all the Spotify playlists I have used to summarize a specific genre in general. 



| Playlist Name       | Number of songs | 
|---------------------|:---------------:|
| Heavy Metal         |               60|               
| Pop Internacional   |               60|               
| Pure Pop Punk       |               50|               
| Rock Classics       |              150|             
| Ultimate Indie      |               62|               
                                                                     